


# model_development.py

# Importing necessary libraries
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns
import os

# List of assets
assets = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'SPY', 'GLD', 'BTC-USD']

# Load the data
def load_data(assets):
    data = {}
    for asset in assets:
        file_path = f'../data/{asset}_enhanced_data.csv'
        try:
            df = pd.read_csv(file_path, index_col='Date', parse_dates=True)
            data[asset] = df
        except FileNotFoundError:
            print(f"File not found for {asset}: {file_path}")
        except pd.errors.ParserError:
            print(f"Parsing error for {asset}: {file_path}")
    return data

# Dictionary to store the evaluation metrics
metrics = {
    'Asset': [],
    'Model': [],
    'Metric': [],
    'Value': []
}

# Function to append metrics
def append_metrics(asset, model_name, metric_name, metric_value):
    metrics['Asset'].append(asset)
    metrics['Model'].append(model_name)
    metrics['Metric'].append(metric_name)
    metrics['Value'].append(metric_value)

# Function to train and evaluate models with cross-validation
def train_and_evaluate_model(asset, df):
    print(f"--- Training and Evaluation for {asset} ---")

    # Select features and target
    features = ['Volume', 'Daily Return', 'MA20', 'MA50', 'RSI', 'MACD', 'Signal Line', 'Volatility']
    target = 'Close'
    
    X = df[features]
    y = df[target]

    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Standardize the features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Initialize models
    models = {
        'Linear Regression': LinearRegression(),
        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
        'Support Vector Regressor': SVR(kernel='rbf')
    }

    # Define cross-validation strategy
    kfold = KFold(n_splits=5, random_state=42, shuffle=True)

    # Train and evaluate each model
    for model_name, model in models.items():
        print(f"\nModel: {model_name}")
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
        
        mse = mean_squared_error(y_test, y_pred)
        mae = mean_absolute_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

        # Store the metrics
        append_metrics(asset, model_name, 'MSE', mse)
        append_metrics(asset, model_name, 'MAE', mae)
        append_metrics(asset, model_name, 'R2', r2)

        # Store the metrics
        # metrics['Asset'].append(asset)
        # metrics['Model'].append(model_name)
        # metrics['Metric'].append('MSE')
        # metrics['Value'].append(mse)
        
        # metrics['Asset'].append(asset)
        # metrics['Model'].append(model_name)
        # metrics['Metric'].append('MAE')
        # metrics['Value'].append(mae)
        
        # metrics['Asset'].append(asset)
        # metrics['Model'].append(model_name)
        # metrics['Metric'].append('R2')
        # metrics['Value'].append(r2)

        
        
        print(f"Mean Squared Error: {mse}")
        print(f"Mean Absolute Error: {mae}")
        print(f"R-squared: {r2}")

        # Cross-validation scores
        cv_mse = cross_val_score(model, X_train_scaled, y_train, cv=kfold, scoring='neg_mean_squared_error')
        cv_mae = cross_val_score(model, X_train_scaled, y_train, cv=kfold, scoring='neg_mean_absolute_error')
        cv_r2 = cross_val_score(model, X_train_scaled, y_train, cv=kfold, scoring='r2')
        
        print(f"Cross-validated Mean Squared Error: {np.mean(-cv_mse)}")
        print(f"Cross-validated Mean Absolute Error: {np.mean(-cv_mae)}")
        print(f"Cross-validated R-squared: {np.mean(cv_r2)}")

        # Store cross-validated metrics
        # append_metrics(asset, model_name, 'CV MSE', np.mean(-cv_mse))
        # append_metrics(asset, model_name, 'CV MAE', np.mean(-cv_mae))
        # append_metrics(asset, model_name, 'CV R2', np.mean(cv_r2))
        
        # Plot predictions vs actual values
        plt.figure(figsize=(5, 3))
        plt.scatter(y_test.index, y_test, label='Actual', color='blue', marker='o', s=1, alpha=0.6)
        plt.scatter(y_test.index, y_pred, label='Predicted', color='red', marker='s', s=1, alpha=0.6)
        plt.title(f"{model_name} - {asset}", fontsize=10)
        plt.xlabel("Date", fontsize=8)
        plt.ylabel("Close Price", fontsize=8)
        plt.legend(loc='best', fontsize=6)
        plt.grid(True)
        plt.tight_layout()
        plt.show()

# Load data
data = load_data(assets)

# Train and evaluate models for each asset
for asset, df in data.items():
    train_and_evaluate_model(asset, df)


# Convert the metrics dictionary to a DataFrame
metrics_df = pd.DataFrame(metrics)

# Set a style for the plots
sns.set(style="whitegrid")

# Create bar plots for each asset
for asset in assets:
    asset_metrics = metrics_df[metrics_df['Asset'] == asset]
    
    plt.figure(figsize=(10, 6))
    
    # Create a bar plot
    bar_plot = sns.barplot(x='Model', y='Value', hue='Metric', data=asset_metrics, palette='Set2')
    
    # Add title and labels with appropriate font sizes
    plt.title(f"Evaluation Metrics for {asset}", fontsize=16, weight='bold')
    plt.xlabel("Model", fontsize=12)
    plt.ylabel("Value", fontsize=12)
    
    # Customize the legend
    legend = plt.legend(title='Metric', fontsize=10)
    legend.set_title('Metric', prop={'size':12, 'weight':'bold'})
    
    # Customize the axes ticks
    bar_plot.tick_params(axis='x', labelsize=10)
    bar_plot.tick_params(axis='y', labelsize=10)
    
    # Add value labels on the bars with reduced decimal places
    for p in bar_plot.patches:
        height = p.get_height()
        if height > 0.01:  # Only annotate significant values to avoid clutter
            bar_plot.annotate(f'{height:.2f}',  # Adjust decimal places as needed
                              (p.get_x() + p.get_width() / 2., height),
                              ha = 'center', va = 'bottom',  # Position at bottom to avoid overlap
                              xytext = (0, 5),  # Adjust position to avoid overlap
                              textcoords = 'offset points',
                              fontsize=10, color='black')
    
    plt.tight_layout()
    plt.show()




